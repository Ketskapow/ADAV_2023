---
title: "Assignment_1_P1"
author: "DaniÃ«l Scheeper"
date: "`r Sys.Date()`"
output: pdf_document
---

## Introduction problem ##
One of the most popular drinks in the world, coffee appeals to our senses with its complex taste profiles and rich scent. Coffee's flavor is the result of a complex interaction of several elements, including the brewing method and the region from where the beans were harvested. For coffee lovers, industry experts, and researchers looking to improve the whole coffee experience, understanding the factors that affect coffee flavor is essential. In this work, we use a data science methodology to disentangle the various factors that affect coffee flavor, utilizing the power of statistics to find undiscovered patterns.

Domain knowledge about coffee and about what influences the taste:
Based on our preliminary research by reviewing several articles (INSERT FOOTNOTE ON ARTICLES), we concluded the following influential factors of the taste of coffee that overlap our available features:
- Variety: Although not as simple as the difference between Arabica and Robusta, variety is said to play an important role in determining the taste
- Origin: The geographical region in which coffee is grown can have a big impact on how it tastes. The distinctive flavor characteristics of coffee from various places are influenced by a variety of factors, including terroir, soil composition, climate, and altitude.
- Processing: Following the selection of a coffee cherry, the coffee seed must be dried before being transported and subsequently roasted by a neighborhood artisan roaster. The methods used to do this can differ greatly and have a significant impact on how the coffee ultimately tastes. 
- Farm practices: The farming methods used on the farm where the coffee is grown is said to have a significant impact on how the coffee tastes. The crop's nature is ultimately going to be impacted by everything, including the usage of herbicides, planting techniques, and trimming schedules.

Articles used (to be added in footnote):
https://capecoffeebeans.co.za/blogs/cape-coffee-blog/77091524-7-factors-that-influence-coffee-flavour
https://www.javapresse.com/blogs/buying-coffee/brief-history-of-coffee#:~:text=But%2C%20the%20reality%20is%2C%20coffee,back%20as%20500%20years%20ago.
https://ictcoffee.com/understanding-coffee-flavors-what-factors-affect-coffee-bean-quality/

Based on our preliminary research, we expect the taste of the coffee, quantified by the total cup points, to be influenced by the variety, origin, processing and farming techniques. Further research will accept or reject this hypothesis.

#### Research question:
In order to identify the most influential factors of coffee taste, the following research question is formulated:
Which features have the greatest influence on the taste of coffee, as measured by the coffee quality rating, using the Coffee Quality Database from the Coffee Quality Institute (CQI)?

#### Methodology
We'll use the Kaggle dataset, specifically the "merged_data_cleaned.csv" file from the CQI's Coffee Quality Database, to look into this subject. This dataset includes a plethora of data on a variety of aspects of coffee, such as sensory assessments, bean qualities, processing techniques, and more. We seek to find the key characteristics that greatly influence coffee's flavor and add to its overall quality rating by utilizing data science methodologies. We will use linear regression using the best subset selection and shrinkage methods, specifically LASSO (Least Absolute Shrinkage and Selection Operator) and ridge regression. By using these statistical methods, we want to identify the critical elements that affect how coffee tastes as determined by the coffee quality rating (total cup points).

#### Variables used 
For the selected model, we have selected the following variables:

Dependent variables:
Total cup points: Number of points the final product coffee has stored by the CQI jury (1-100 points; 100 being the highest score)

Independent variables:
Country of origin: Where the coffee was farmed
Harvest year: The year the coffee was harvested
Variety: Which variety of coffee (Arabica / Robusta)
Processing method: Which processing method was used before roasting
Color: Which color the coffee in the cup has
Category one defects: How many cat. 1 defects the coffee has (significant defect on taste, aroma, visual appearance)
Category two defects: How many cat. 2 defects the coffee has (minor defects like chipped, partial black, shells or husks, and underdeveloped beans)
Mean altitude (m): At which mean altitude this coffee is cultured


First, we load in the libraries which are used throughout the analysis
```{r packages, warning = FALSE, message = FALSE}
library(tidyverse) # metapackage of all tidyverse packages
library(ggplot2) # For plotting visualizations
library(caret) # For regression functions
library(glmnet) # For shrinkage methods
library(naniar) # for plotting missing values - does not work yet
```


We set a seed to ensure reproducability
```{r seed, include = FALSE}
set.seed(42)
```

#### Data cleaning 
After getting familiar with the dataset, we identified the following steps for data cleaning:
1.	Missing Values: We checked for missing values in the dataset. As the next step, we proceeded to remove all rows that were missing information about the total cup points. 
2.	Selecting Relevant Variables: We decided which variables are most relevant to our analysis. We kept only the variables that we found important for our research.
3.	Handling Harvest.Year: We observed an issue with some cells containing two dates or a month instead of just a year. We addressed this issue as well as we transformed the Harvest Date variable into a continuous.
4.	Standardizing Country.of.Origin: In the variable "Country.of.Origin," we replaced the values "United States (Hawaii)" and "United States (Puerto Rico)" with "Hawaii" and "Puerto Rico," respectively. 
5.	Adjusting Altitude Data: We noticed that some entries in the "altitude_mean_meters" variable were unrealistic. We replaced the unrealistic altitude values with proper information. 
After implementing these data cleaning steps, we considered the remaining variables to be sufficiently clean for our analysis.
```{r data cleaning}
#load in data and remove index column
coffee_data <- read_csv("merged_data_cleaned.csv") %>% 
  select(-1)

# check for number of NAs in each variable
missing_counts <- colSums(is.na(coffee_data))
missing_counts

# clean Harvest Year variable (turn it into continuous variable (take only last year if two years are given)
continuous_variable <- numeric(nrow(coffee_data))
for (i in 1:nrow(coffee_data)) {
  entry <- as.character(coffee_data$Harvest.Year[i])
  last_year <- substring(entry, nchar(entry) - 3)
  continuous_variable[i] <- as.numeric(last_year)
}
coffee_data$Harvest.Year <- continuous_variable
coffee_data$Harvest.Year <- as.numeric(coffee_data$Harvest.Year)

# replace "United States (Hawaii)" and "United States (Puerto Rico)"  with "Hawaii" and "Puerto Rico" in Country.of.Origin
coffee_data$Country.of.Origin <- gsub("United States \\(Hawaii\\)", "Hawaii", coffee_data$Country.of.Origin)
coffee_data$Country.of.Origin <- gsub("United States \\(Puerto Rico\\)", "Puerto Rico", coffee_data$Country.of.Origin)

# keep everything but quality measures and (presumably) non-informative columns 
coffee_data_cleaned <- coffee_data %>%
  select(Country.of.Origin, Harvest.Year, Variety, Processing.Method, Color, Category.One.Defects, Category.Two.Defects, altitude_mean_meters, Total.Cup.Points)

# remove cups where total cup points is missing
coffee_data_cleaned <- coffee_data_cleaned %>% 
  na.omit(select(., Country.of.Origin, Harvest.Year, Variety, Processing.Method, Color, altitude_mean_meters, Total.Cup.Points))

nrow(coffee_data_cleaned)
head(coffee_data_cleaned)

print(coffee_data_cleaned)

```

```{r}
ggplot(coffee_data_cleaned, aes(x = altitude_mean_meters)) +
  geom_histogram()
#There are several values here that are higher than the highest point on earth, that's an entry error. But we can fix it.
subset_df <- subset(coffee_data, altitude_mean_meters > 9000)
print(subset_df[, c("Farm.Name", "Altitude", "altitude_mean_meters")])

#You can see that the values which are above 9000 are entry errors. We can fix that like so.
coffee_data_cleaned$altitude_mean_meters <- ifelse(coffee_data_cleaned$altitude_mean_meters == 190164.000, 1901.64, coffee_data_cleaned$altitude_mean_meters)

coffee_data_cleaned$altitude_mean_meters <- ifelse(coffee_data_cleaned$altitude_mean_meters %in% c(110000.000, 11000.000), 1100.000, coffee_data_cleaned$altitude_mean_meters)


#Check the new distribution
ggplot(coffee_data_cleaned, aes(x = altitude_mean_meters)) +
  geom_histogram()

```

#### Create plots 
``` {r plots}
# Create four groups for Total.Cup.Points
coffee_data_cleaned$Group_Total.Cup.Points <- cut(coffee_data_cleaned$Total.Cup.Points,
                         breaks = c(60, 70, 80, 90, 100),
                         labels = c("60-70", "70-80", "80-90", "90-100"),
                         include.lowest = TRUE)

# Create the graph 1
ggplot(coffee_data_cleaned, aes(x = altitude_mean_meters, y = Color, colour = Group_Total.Cup.Points)) +
  geom_point() +
  labs(x = "Altitude (meters)", y = "Color", colour = "Total.Cup.Points Groups") +
  ggtitle("Relationship between Altitude, Color, and Total Cup Points")


# Calculate the average defects
average_defects <- coffee_data_cleaned %>%
  group_by(Group_Total.Cup.Points) %>%
  summarise(Average_Category.One.Defects = mean(Category.One.Defects),
            Average_Category.Two.Defects = mean(Category.Two.Defects))

# Reshape the data for plotting
average_defects_long <- average_defects %>%
  gather(Defect_Category, Average_Defects, -Group_Total.Cup.Points)

# Create the graph 2
ggplot(average_defects_long, aes(x = Group_Total.Cup.Points, y = Average_Defects, fill = Defect_Category)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "Total.Cup.Points", y = "Average Number of Defects", fill = "Defect Category") +
  ggtitle("Average Number of Defects by Group Total Cup Points") +
  theme_bw()

# Create the graph 3
ggplot(coffee_data_cleaned, aes(x = Variety, fill = Processing.Method)) +
  geom_bar() +
  labs(x = "Variety", y = "Count", fill = "Processing Method") +
  ggtitle("Processing Method Distribution by Coffee Variety") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Calculate the average total cup points by Harvest Year
average <- coffee_data_cleaned %>%
  group_by(Harvest.Year) %>%
  summarise(Average = mean(Total.Cup.Points))

# Create the plot 4 
ggplot(average, aes(x = Harvest.Year, y = Average)) +
  geom_line() +
  geom_point() +
  labs(x = "Harvest Year", y = "Average Total Cup Points") +
  ggtitle("Average Total Cup Points by Harvest Year") +
  theme_bw()

# Create a function that switches country to a continent 
country_to_continent <- function(country) {
  switch(country,
         "Ethiopia" = "Africa",
         "China" = "Asia",
         "United States" = "North America",
         "Costa Rica" = "North America",
         "Mexico" = "North America",
         "Brazil" = "South America",
         "Uganda" = "Africa",
         "Taiwan" = "Asia",
         "Kenya" = "Africa",
         "Thailand" = "Asia",
         "Colombia" = "South America",
         "Panama" = "North America",
         "Guatemala" = "North America",
         "El Salvador" = "North America",
         "Indonesia" = "Asia",
         "Tanzania, United Republic Of" = "Africa",
         "Honduras" = "North America",
         "Nicaragua" = "North America",
         "Puerto Rico" = "North America",
         "Haiti" = "North America",
         "Vietnam" = "Asia",
         "Philippines" = "Asia",
         "Rwanda" = "Africa",
         "Malawi" = "Africa",
         "Laos" = "Asia",
         "Myanmar" = "Asia",
         "Peru" = "South America",
         "India" = "Asia",
         "Unknown" = "Unknown"
  )
}

# Add a new variable 'Continent' 
coffee_data_cleaned$Continent <- sapply(coffee_data_cleaned$Country.of.Origin, country_to_continent)

```

```{r split}
# 60% partition
partitions_60 <- createDataPartition(y = coffee_data_cleaned$Total.Cup.Points, p = 0.6, list = FALSE)

coffee_train <- coffee_data_cleaned[partitions_60, ]

remaining_data <- coffee_data_cleaned[-partitions_60, ]

# 20% partition
partitions_20 <- createDataPartition(y = remaining_data$Total.Cup.Points, p = 0.5, list = FALSE)

coffee_valid <- remaining_data[partitions_20, ]

coffee_test <- remaining_data[-partitions_20, ]
```

```{r}
# Tag all datasets and combine the data
coffee_train$Group <- "Train"
coffee_valid$Group <- "Validate"
coffee_test$Group <- "Test"
combined_data <- rbind(coffee_train, coffee_valid, coffee_test)



# Create a simple histogram with all selected data
library(ggplot2)
ggplot(combined_data, mapping = aes(x = Total.Cup.Points, fill = Group)) +
 geom_density(alpha = 0.5) +
 labs(x = "Total cup points", y = "%", title = 'Total cup points per dataset') +
 scale_fill_manual(values = c("Train" = "lightblue", "Validate" = "lightgreen", "Test" = "red")) +
 theme_minimal()
```

```{r}
#Define lm_mse function for later model evaluation purposes
lm_mse <- function(formula, train_data, valid_data) {
  y_name <- as.character(formula)[2]
  y_true <- valid_data[[y_name]]
  
  lm_fit <- lm(formula, train_data)
  y_pred <- predict(lm_fit, newdata = valid_data)
  
  mean((y_true - y_pred)^2)
}
```

```{r}
#Create matrix for glmnet function and remove intercept created by function
x_train <- model.matrix(Total.Cup.Points ~ Country.of.Origin + Variety + Processing.Method + Color, data = coffee_train)
x_train <- x_train[, -1]

#Make df for continuous variables since model.matrix can't parse those
contvar <- coffee_train %>%
  select(-Country.of.Origin, -Variety, -Processing.Method, -Color, -Total.Cup.Points, -Group)

#turn df into matrix
x_contvar <- data.matrix(contvar)

#bind columns to have complete matrix
x_train <- cbind(x_train, x_contvar)
```

```{r}
#make lasso regression
LassoReg1<- glmnet(x_train, coffee_train$Total.Cup.Points, family = "gaussian", lambda = 15)
```

```{r}
LassoReg1$beta
```
```{r}
#Create matrix for glmnet function and remove intercept created by function
x_valid <- model.matrix(Total.Cup.Points ~ Country.of.Origin + Variety + Processing.Method + Color, data = coffee_valid)
x_valid <- x_valid[, -1]

#Make df for continuous variables since model.matrix can't parse those
contvar_valid <- coffee_valid %>%
  select(-Country.of.Origin, -Variety, -Processing.Method, -Color, -Total.Cup.Points, -Group)

#turn df into matrix
x_contvar_valid <- data.matrix(contvar_valid)

#bind columns to have complete matrix
x_valid <- cbind(x_valid, x_contvar_valid)

#bind rows to have combined data
x_combined <- rbind(x_valid, x_train)
coffee_combined <- bind_rows(coffee_valid, coffee_train)
```


```{r}
cv <- cv.glmnet(x_train, coffee_train$Total.Cup.Points, family = "gaussian", alpha = 1, nfolds = 15)

best_lambda <- cv$lambda.min
```

```{r}
#make lasso regression
LassoReg2<- glmnet(x_train, coffee_train$Total.Cup.Points, family = "gaussian", lambda = best_lambda)
LassoReg2$beta
```

